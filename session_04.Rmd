---
title: "Session 4: Data Management"
subtitle: "Learning Objectives:"
---

- Learn to recode, transform and create new useful variables.
- Learn to group and summarise data into useful bits of information.
- Learn how to report and visualize different types of data.


# Resources

## Cheatsheets

- [Data transformation](https://github.com/rstudio/cheatsheets/raw/master/data-transformation.pdf)
- [Data visualization](https://github.com/rstudio/cheatsheets/raw/master/data-visualization-2.1.pdf)

## Readings
- [Exploratory Data Analysis](https://r4ds.had.co.nz/exploratory-data-analysis.html)

## Practice

- [Data visualization with ggplot2](https://learn.datacamp.com/courses/introduction-to-data-visualization-with-ggplot2)
- [Exploratory Data Analysis](https://learn.datacamp.com/courses/exploratory-data-analysis-in-r)
- [Data Cleaning](https://learn.datacamp.com/courses/cleaning-data-in-r)


# Data Management

Once we know more about our dataset, it is time to more fix the identified flaws in the data and begin to extract useful insights. We continue the explore, transform and visualize loop to learn more from the data and create useful variables also known as features. This process can easily take 80% or more of a researcher's time.

We will continue to use dplyr's verbs to manipulate the data.

- `select()` picks variables based on their names.
- `filter()` picks cases based on their values.
- `mutate()` adds new variables that are functions.
- `arrange()` changes the ordering of the rows.
- `rename()` changes the name of individual variables.

We will focus on data aggregation functions:

- `summary()` produces result summaries based on the class of the object.
- `groub_by()` group by one or more variables.
- `summarise()` summarise each group to fewer rows.

![](https://uw-madison-datascience.github.io/2019-09-11-uwmadison-dc/slides/dplyr/dplyr-4.png "")


## Types of data

We have seen that there are different types of data in R (numeric, character, factor, logical, ...). In the real world, we can group data in two broad families:

**Discrete** data can only take a finite number of values.

- eg. The number of students in a class.

**Continuous** data can take an infinite number of values.

- eg. The height of a student.

## Levels of Measurement

We can further divide each of these data types into four families:

**Nominal:** Differences of kind. There is no mathematical relationship between the values.

eg. Political parties.

**Ordinal:** Differences of degree. There is a mathematical relationships among the values. Symbols like <, ≤, =, ≥, and > have meaning but the distance between two elements is not constant.

eg. Levels of education.

**Interval:** There is a mathematical relationship among the elements and the distance between them is constant but they do not have a meaningful zero value.

eg. Feelings thermometer (0 to 100).

**Ratio:** Similar to the interval variables but they have a meaningful zero value.

eg. Feelings thermometer (-50 to 50)

We can notice that each subsequent level of measurement has the properties of levels before it. For more details on this see [Chapter 1, Siegel, 2013](https://press.princeton.edu/books/paperback/9780691159171/a-mathematics-course-for-political-and-social-research).

Understanding these variable types helps us recode the variables in our datasets into their appropriate types in order to extract proper insights or create useful features for our predictive models. To recode the variables we will often use a combination of functions such as:

- `mutate()`
- `as.numeric()`
- `as.character(`)
- `as.factor()`
- `as.logical()`

# Hack Time!

```{r klippy, echo=FALSE, include=TRUE}
klippy::klippy()
```

```{r eval=FALSE}
# Session 4: Data Management  --------------------------------------------------

# Getting Started ==============================================================
# Load the tidyverse package
...

# Identify the path to a `ts_2016.rds` dataset on your machine
data_path <- "..."

# Read your data and save it into an object called `dataset`
dataset <- ...

# Let's work on a subset of the dataset using meaningful names
tmp_data <- dataset %>%
  select(
    V161031,   # vote_intent
    V161086,   # ft_democrat
    V161087,   # ft_republican
    V161126,   # ideology
    V161181,   # defense
    V161184,   # healthcare
    V161178,   # government
    V161155,   # party_id
    V162034a   # actual_vote
  ) %>%
  rename(
    "vote_intent"   = "V161031",
    "ft_democrat"   = "V161086",
    "ft_republican" = "V161087",
    "ideology"      = "V161126",
    "defense"       = "V161181",
    "healthcare"    = "V161184",
    "government"    = "V161178",
    "party_id"      = "V161155",
    "actual_vote"   = "V162034a"
  )

# Let's focus on the voting intention variable for now.
# Peek at the variable in the newly created dataset
head(...)

# How would you do this using the tidyverse pipes?
...

# Plot the vote_intent variable
  ggplot(tmp_data, aes(x = ...)) +
  geom_bar()

# What's wrong with this variable?

# The summary function can also help to see flaws in the data.
summary(...)


# Data Cleaning ===============================================================
# Handle missing values and save it into a new object
clean_data <- tmp_data %>%
  filter(... > ...)

# Plot gain
ggplot(clean_data, aes(x = vote_intent)) +
geom_bar()

# Note that a whole course could be given on how to handle missing values.
# For now we are just going to filter out those observations.

# What is the current class of this variable?
...

# Is this class appropriate for this variable? If no, change its the type.
clean_data <- tmp_data %>%
  filter(vote_intent > 0) %>%
  mutate(... = as . ...(...))

# Let's look again
ggplot(clean_data, aes(x=vote_intent)) +
geom_bar()

# What do the 1-8 numbers mean? Keep only what's relevant.
clean_data <- tmp_data %>%
  filter(vote_intent > 0, ...) %>%
  mutate(vote_intent = as.character(vote_intent))

# Check again
ggplot(clean_data, aes(x=vote_intent)) +
geom_bar()

# Recode the values of the variable
clean_data <- tmp_data %>%
  filter(vote_intent > 0, vote_intent < 5) %>%
  mutate(vote_intent = as.character(vote_intent)) %>%
  mutate(
    ... = recode(
      vote_intent,
      "1" = "...",
      "..." = "...",
      "..." = "...",
      "..." = "..."
    )
  )

# Plot again
ggplot(clean_data, aes(x=vote_intent)) +
geom_bar()


# Grouping, aggregating and summarising ========================================

# How can we get the exact frequencies ?
# This is where `groub_by()` and `summarise()` will come in handy!

clean_data %>%
  group_by(...) %>%
  summarise(... = n())

# Notice that we did not save the information in an object.
# Instead we printed the information directly in the console.

vote_intent_freq <- clean_data %>%
  ...

# What is the predicted vote share for each candidate using voting intentions?

clean_data %>%
  group_by(vote_intent) %>%
  summarise(freq = n()) %>%
  ...(
    prop = ...
  )

# How good are those numbers relative to the actual numbers?
# Check Wikipedia for the actual numbers and compare.

# Note that if we want to reuse the information we should save it!
# Let's do that.

vote_intent_summary <- ...


# Plotting data summaries ======================================================

# Now let's make an actual plot with the percentages
ggplot(..., aes(x=...)) +
geom_bar()

# What's wrong here?

# Try again using geom_col() instead of geom_bar
ggplot(vote_intent_summary, aes(x=vote_intent, y=...))+
geom_...()

ggplot(vote_intent_summary, aes(x=vote_intent, y=prop))+
geom_col()

# Let's quickly clean liberal-conservative self placement variable.
clean_data <- clean_data %>%
  filter(
    ideology > 0,
    ideology < 8
  ) %>%
  mutate(
    ideology = as. ... (...)
  )

# Peek at the variables
clean_data %>%
  select(vote_intent, ideology) %>%
  # WARNING: summary() is a different function summarise()!
  summary()

# What is the average (mean) ideology per voting intention group?
clean_data %>%
  group_by(...) %>%
  summarise(
    ... = ...(...)
  )

# Does this make sense?

# Here's a more advanced way of summarizing this information visually
# Saving intermediary means
idl_means <- clean_data %>%
  group_by(vote_intent) %>%
  summarise(
    avg = mean(ideology)
  )

ggplot(clean_data, aes(x = ideology, y = ..prop.., group=vote_intent)) +
  geom_bar() +
  facet_wrap(~vote_intent) +
  geom_vline(
    data=idl_means,
    aes(xintercept=avg), color="red", linetype=2) +
  scale_x_discrete(
    limits=c("Ext. liberal", "", "", "Moderate", "", "", "Ext. conservative")
  ) +
  labs(
    x = "Self placement",
    y = "Proportion"
  ) +
  theme_bw()
```

# Requirements
- Complete [Challenge 3: The Explorer](https://classroom.github.com/a/f4bspIRM)

